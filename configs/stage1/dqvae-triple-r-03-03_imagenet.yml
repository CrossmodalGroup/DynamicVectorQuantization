model:
  base_learning_rate: 4.5e-06
  target: models.stage1_dynamic.dqvae_triple_feat.TripleGrainVQModel
  params:
    encoderconfig:
      target: modules.dynamic_modules.EncoderTriple.TripleGrainEncoder
      params:
        ch: 128
        ch_mult: [1,1,2,2,4,4]
        num_res_blocks: 2
        attn_resolutions: [8,16,32]
        dropout: 0.0
        resamp_with_conv: true
        in_channels: 3
        resolution: 256
        z_channels: 256
        router_config:
          target: modules.dynamic_modules.RouterTriple.TripleGrainFeatureRouter
          params:
            num_channels: 256
            normalization_type: group-32
            gate_type: 2layer-fc-SiLu
    decoderconfig:
      target: modules.dynamic_modules.DecoderPositional.Decoder
      params:
        ch: 128
        in_ch: 256
        out_ch: 3
        ch_mult: [1,1,2,2]
        num_res_blocks: 2
        resolution: 256
        attn_resolutions: [32]
        latent_size: 32
        window_size: 2
        position_type: fourier+learned
    lossconfig:
      target: modules.losses.vqperceptual_multidisc.VQLPIPSWithDiscriminator
      params:
        disc_start: 0
        disc_config:
          target: modules.discriminator.model.NLayerDiscriminator
          params:
            input_nc: 3
            ndf: 64
            n_layers: 3
            use_actnorm: false
        disc_init: true
        codebook_weight: 1.0
        pixelloss_weight: 1.0
        disc_factor: 1.0
        disc_weight: 1.0
        perceptual_weight: 1.0
        disc_conditional: false
        disc_loss: hinge
        disc_weight_max: 0.75
        budget_loss_config:
          target: modules.dynamic_modules.budget.BudgetConstraint_NormedSeperateRatioMSE_TripleGrain
          params:
            target_fine_ratio: 0.3
            target_median_ratio: 0.3
            gamma: 1.0
            min_grain_size: 8
            median_grain_size: 16
            max_grain_size: 32

    vqconfig:
      target: modules.vector_quantization.quantize2_mask.VectorQuantize2
      params:
        codebook_size: 1024
        codebook_dim: 256
        channel_last: false
        accept_image_fmap: true
        commitment_beta: 0.25
        decay: 0.99
        restart_unused_codes: True
    quant_before_dim: 256
    quant_after_dim: 256
    quant_sample_temperature: 0.0
    image_key: image
    monitor: val_rec_loss
    warmup_epochs: 0.1
    scheduler_type: linear-warmup_cosine-decay

data:
  target: data.build.DataModuleFromConfig
  params:
    batch_size: 30
    num_workers: 8
    train:
      target: data.imagenet.ImageNetTrain
      params:
        config:
          is_eval: False
          size: 256
    validation:
      target: data.imagenet.ImageNetValidation
      params:
        config:
          is_eval: True
          size: 256